# Script de nettoyage et d'extraction des donn√©es
import pandas as pd

import pandas as pd

#  D√©finition des chemins de fichiers
input_file = "../data/filtered_tweets_engie.csv"
output_file = "../data/cleaned_tweets.csv"

#  √âtape 1 : Chargement des donn√©es
print(" Chargement des tweets...")
df = pd.read_csv(input_file, sep=";")

# Affichage propre de l'aper√ßu des donn√©es
print("\n Aper√ßu des premi√®res lignes :")
print(df.head(3))  # jute 3 lignes 

# V√©rifier les infos g√©n√©rales du dataset
print("\n Infos sur le dataset avant nettoyage :")
df.info()

#  √âtape 2 : Nettoyage des donn√©es
df.rename(columns={'full_text': 'tweet_text', 'created_at': 'date', 'id': 'user_id'}, inplace=True)

# Supprimer les tweets venant de "ENGIEpartFR" et "ENGIEgems" dans screen_name
df = df[~df['screen_name'].str.contains("ENGIEpartFR|ENGIEgems", case=False, na=False)]

# Supprimer les lignes avec des valeurs nulles sur des colonnes essentielles
df.dropna(subset=['tweet_text', 'date', 'user_id'], inplace=True)

#  Correction : Conversion de la date avec UTC + gestion erreurs
df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)

# Si des dates n'ont pas pu √™tre converties, on les retire
if df['date'].isnull().sum() > 0:
    print(f"\n Suppression de {df['date'].isnull().sum()} lignes avec date non valide.")
    df.dropna(subset=['date'], inplace=True)

# Convertir user_id en texte et nettoyer
df['user_id'] = df['user_id'].astype(str).str.replace(",", "")

#  √âtape 3 : Extraction d'infos utiles
df['hour'] = df['date'].dt.hour
df['tweet_length'] = df['tweet_text'].apply(len)

#  √âtape 4 : √âvaluation de la criticit√© des tweets
keywords_urgence = ["panne", "urgence", "scandale", "incident"]
keywords_eleve = ["r√©clamation", "erreur", "probl√®me"]
keywords_modere = ["facture", "service", "d√©lai"]

def classifier_criticite(tweet):
    text = tweet.lower()
    if any(word in text for word in keywords_urgence):
        return 4  # Urgent
    elif any(word in text for word in keywords_eleve):
        return 3  # √âlev√©
    elif any(word in text for word in keywords_modere):
        return 2  # Mod√©r√©
    else:
        return 1  # Faible

df['criticite'] = df['tweet_text'].apply(classifier_criticite)

#  Garder les doublons, mais sans les tweets ENGIEpartFR ou ENGIEgems
df = df.sort_values(by='date', ascending=False)  # Juste pour l'organisation visuelle

# üìå √âtape 5 : V√©rifications finales et export
print("\n Aper√ßu final des donn√©es apr√®s suppression des tweets ENGIEpartFR et ENGIEgems :")
print(df[['screen_name', 'tweet_text', 'hour', 'tweet_length', 'criticite']].head(5))

# Sauvegarde des donn√©es nettoy√©es

df.to_csv(output_file, index=False)
print(f"\n Donn√©es nettoy√©es et sauvegard√©es : {output_file}")
