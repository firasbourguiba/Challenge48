{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>criticite</th>\n",
       "      <th>Inconfort</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Urgence</th>\n",
       "      <th>Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189684000000000011534336</td>\n",
       "      <td>lescausesjustes</td>\n",
       "      <td>AInnovation</td>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>@ENGIEgroup @ENGIEpartFR pour l'amour du ciel,...</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>N√©gatif</td>\n",
       "      <td>True</td>\n",
       "      <td>08:09:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18967000000000000262144</td>\n",
       "      <td>Leoletonneau</td>\n",
       "      <td>Tigre &amp; Dragon üêØ üêâ</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>@ENGIEpartFR vraiment des escrocs, des montant...</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>N√©gatif</td>\n",
       "      <td>True</td>\n",
       "      <td>23:25:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189662999999999998164992</td>\n",
       "      <td>SouareFirst</td>\n",
       "      <td>So First</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>@ENGIEpartFR bonjour engie les voleurs ! Atten...</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>N√©gatif</td>\n",
       "      <td>True</td>\n",
       "      <td>18:47:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189661999999999987941376</td>\n",
       "      <td>julien_ducerf</td>\n",
       "      <td>Julien Ducerf</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>@ENGIEpartFR c'est du harc√®lement pour augment...</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>N√©gatif</td>\n",
       "      <td>False</td>\n",
       "      <td>17:50:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189658000000000014155776</td>\n",
       "      <td>djofthp</td>\n",
       "      <td>jojodamido</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>@ENGIEpartFR on vous parle</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Neutre</td>\n",
       "      <td>False</td>\n",
       "      <td>15:24:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id      screen_name                name       date  \\\n",
       "0  189684000000000011534336  lescausesjustes         AInnovation 2025-03-04   \n",
       "1   18967000000000000262144     Leoletonneau  Tigre & Dragon üêØ üêâ 2025-03-03   \n",
       "2  189662999999999998164992      SouareFirst            So First 2025-03-03   \n",
       "3  189661999999999987941376    julien_ducerf       Julien Ducerf 2025-03-03   \n",
       "4  189658000000000014155776          djofthp          jojodamido 2025-03-03   \n",
       "\n",
       "                                          tweet_text  tweet_length  criticite  \\\n",
       "0  @ENGIEgroup @ENGIEpartFR pour l'amour du ciel,...           113          1   \n",
       "1  @ENGIEpartFR vraiment des escrocs, des montant...           131          1   \n",
       "2  @ENGIEpartFR bonjour engie les voleurs ! Atten...           184          1   \n",
       "3  @ENGIEpartFR c'est du harc√®lement pour augment...           167          2   \n",
       "4                         @ENGIEpartFR on vous parle            26          1   \n",
       "\n",
       "   Inconfort Sentiment Urgence     Hours  \n",
       "0       90.0   N√©gatif    True  08:09:58  \n",
       "1      100.0   N√©gatif    True  23:25:45  \n",
       "2      100.0   N√©gatif    True  18:47:06  \n",
       "3       85.0   N√©gatif   False  17:50:42  \n",
       "4       20.0    Neutre   False  15:24:10  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Charger le DataFrame\n",
    "df = pd.read_csv(r\"C:\\Users\\Harrison\\Challenge48\\data\\cleaned_tweets_with_sentiment.csv\")\n",
    "\n",
    "# Fonction pour extraire les valeurs des cl√©s \"Inconfort\", \"Sentiment\", \"Urgence\"\n",
    "def extract_json_values(json_str):\n",
    "    try:\n",
    "        # Isoler la partie JSON avant \"Explication\" ou autre texte ajout√©\n",
    "        json_part = re.search(r'\\{.*?\\}', json_str, re.S).group(0)\n",
    "\n",
    "        # Nettoyer et parser le JSON\n",
    "        cleaned_str = json_part.replace('\\r\\n', '').replace(\"'\", '\"')\n",
    "        json_dict = json.loads(cleaned_str)\n",
    "\n",
    "        # Renvoyer les valeurs des cl√©s\n",
    "        return json_dict.get(\"Inconfort\"), json_dict.get(\"Sentiment\"), json_dict.get(\"Urgence\")\n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        return None, None, None\n",
    "\n",
    "# Appliquer l'extraction sur la colonne 'sentiment'\n",
    "df['Inconfort'], df['Sentiment'], df['Urgence'] = zip(*df['sentiment'].apply(extract_json_values))\n",
    "\n",
    "# Supprimer l'ancienne colonne 'sentiment'\n",
    "df.drop(columns=['sentiment', 'hour'], inplace=True)\n",
    "\n",
    "# Fonction pour s√©parer la date et l'heure\n",
    "def split_date_time(datetime_str):\n",
    "    try:\n",
    "        date_part, time_part = datetime_str.split(' ')\n",
    "        time_part = time_part.replace('+00:00', '')  # Supprimer le d√©calage horaire\n",
    "        return date_part, time_part\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "# Appliquer la s√©paration sur la colonne 'date'\n",
    "df['date'], df['Hours'] = zip(*df['date'].apply(split_date_time))\n",
    "\n",
    "# Convertir les colonnes au bon format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Convertir en datetime\n",
    "df['Hours'] = pd.to_datetime(df['Hours'], format='%H:%M:%S', errors='coerce').dt.time  # Convertir en time\n",
    "\n",
    "# Convertir 'user_id' en cha√Æne de caract√®res et enlever les z√©ros inutiles\n",
    "df['user_id'] = df['user_id'].apply(lambda x: str(int(x)) if pd.notna(x) else None)\n",
    "\n",
    "# Afficher un aper√ßu du DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Appliquer la fonction d'analyse avec un d√©lai sur les tweets n√©gatifs\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m df_negatifs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_negatifs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_analysis_with_delay_and_retry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Fusionner les r√©sultats dans le DataFrame original `df` en ajoutant la colonne `sentiment_analysis`\u001b[39;00m\n\u001b[0;32m     45\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(df_negatifs[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Harrison\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10033\u001b[0m )\n\u001b[1;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Harrison\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Harrison\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:965\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 965\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\Harrison\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:981\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    983\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    984\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    985\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[82], line 38\u001b[0m, in \u001b[0;36mapply_analysis_with_delay_and_retry\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     36\u001b[0m result \u001b[38;5;241m=\u001b[39m analyse_tweet_with_retry(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Attendre quelques secondes entre les requ√™tes (par exemple, 5 secondes)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ajuste la dur√©e en fonction de la limite de l'API\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Initialisation du client avec la cl√© API\n",
    "client = Mistral(api_key=\"QU9joTThl5C9C8Waz8dgk2Mu9mFT7TaZ\")\n",
    "\n",
    "# Filtrer les tweets n√©gatifs\n",
    "df_negatifs = df[df['Sentiment'] == 'N√©gatif'].copy()\n",
    "\n",
    "# Fonction pour analyser chaque tweet avec gestion des erreurs\n",
    "def analyse_tweet_with_retry(tweet, retries=3, delay=5):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            response = client.agents.complete(\n",
    "                agent_id=\"ag:f685da10:20250310:untitled-agent:5d68c6b9\",  # Remplace par ton ID d'agent\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": tweet\n",
    "                }]\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):  # Si l'erreur est un d√©passement de quota\n",
    "                print(f\"Rate limit exceeded, waiting for {delay} seconds...\")\n",
    "                time.sleep(delay)  # Attente avant de r√©essayer\n",
    "                attempt += 1\n",
    "            else:\n",
    "                print(f\"Une erreur est survenue: {e}\")\n",
    "                raise  # Si l'erreur est autre, relancer l'exception\n",
    "    return None  # Si toutes les tentatives √©chouent\n",
    "\n",
    "# Appliquer la fonction d'analyse avec un d√©lai et gestion des erreurs sur chaque tweet du DataFrame\n",
    "def apply_analysis_with_delay_and_retry(row):\n",
    "    result = analyse_tweet_with_retry(row['tweet_text'])\n",
    "    # Attendre quelques secondes entre les requ√™tes (par exemple, 5 secondes)\n",
    "    time.sleep(5)  # Ajuste la dur√©e en fonction de la limite de l'API\n",
    "    return result\n",
    "\n",
    "# Appliquer la fonction d'analyse avec un d√©lai sur les tweets n√©gatifs\n",
    "df_negatifs['sentiment_analysis'] = df_negatifs.apply(apply_analysis_with_delay_and_retry, axis=1)\n",
    "\n",
    "# Fusionner les r√©sultats dans le DataFrame original `df` en ajoutant la colonne `sentiment_analysis`\n",
    "df = df.merge(df_negatifs[['tweet_text', 'sentiment_analysis']], on='tweet_text', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_reason(text):\n",
    "    # Si le texte est manquant (NaN ou vide), retourne NaN\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # 1. Chercher le motif entre guillemets (ex: \"D√©ception totale\")\n",
    "    match = re.search(r'\"(.*?)\"', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # 2. Chercher le motif entre ast√©risques (ex: **Service m√©diocre**)\n",
    "    match = re.search(r'\\*\\*(.*?)\\*\\*', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # 3. Si aucun motif trouv√©, r√©cup√©rer apr√®s le dernier ':' (si existe)\n",
    "    if ':' in text:\n",
    "        return text.split(':')[-1].strip()\n",
    "\n",
    "    # 4. Sinon, retourner le texte brut (au cas o√π aucun motif ne s'applique)\n",
    "    return text.strip()\n",
    "\n",
    "# Appliquer la fonction d'extraction sur la colonne 'sentiment_analysis'\n",
    "df[\"sentiment_analysis\"] = df[\"sentiment_analysis\"].apply(extract_reason)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
